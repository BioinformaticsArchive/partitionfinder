Rob new search stuff
_________________

TODO
* a problem is that trying all possible splits isn't possible so, I could try this:
    * get an OK starting scheme using GTR+G or LG+G
    * try lumpings and splittings based on e.g.:
        * tree length
        * GTR parameters
        * gamma shape parameter
    * assuming I can make sensible proposals for these (e.g. try this splitting or this lumping)
      then I can easily just cycle through these proposals, maybe quitting if I get through everything without finding improvemnt
      
e.g. pseudocode:

1. Get rough starting scheme (just GTR+G)
2. get list of all subsets in start scheme, and their parameters:
3. propose lumpings based on 2 (for N subsets in start, could propose lumpings to give N-1 all the way down to 1 if I like, or could limit search space to e.g. N-3 or N-4 for efficiency)
4. get list of all subsets with >1 data block
5. propose splittings based on 4 (e.g. for each subset of K datablocks, I could propose the best split into 2, into 3 and up to K. Again, I could limit it to <=4 or 5, for efficiency)
6. Evaluate all proposed splittings and lumpings
7. Choose best one and set to starting scheme, go back to 2

8. Once this is done, run a final thorough loop of neighbour searches, just to make sure

This is probably OK, but it's not clear how helpful it will really be... maybe leave this as an honours/phd project.

DONE
* in new_search: tidy up the greedy algorithm, it's a bit of a mess
* including (but not limited to) putting the 'model_selection' thing into schemes. This is TOO ugly right now!
* AND: neatining up that while loop, which is pretty hideous
* THEN: fix a potential bug in the neighbour analysis, in which if the start_scheme isn't beaten in the first round, it fails
* Run PF on a single subset of a protein alignment, compare to ProtTest and jModeltest
* use Name_fixer2 on large analysed datasets, and start them re-running on the server


Brett test enhancing:
---------------------

TODO 
* Only makes sense to report ONE IC in the greedy algo output...
* make progress part of the reporter too
* change name back to full_name in subset reporting
* Only makes sense to report ONE IC in the greedy algo output...
* make progress part of the reporter too
* change name back to full_name in subset reporting
*
* THEN USE Analysis results to produce a test_object_compartor.
* The write methods for comparining that into AnalysisResults (with epsilon differences)
*
* THEN: Do a folder diff on example folder, making sure that these changes
* produce expactly the same thing!
*
* THEN: ask Rob to double check
*
* THEN: think about using __slots__ in subset and scheme?
* THEN: Consider dropping part_subsets in schemes (only need it for checking...)
* THEN: think about ditching schemes, and subset info?

DONE
* Make the output match (why aren't schemes numbered the same...)
* Only makes sense to report ONE IC in the greedy algo output...
* move path creation into config
* make results member of scheme? or keep a paired list
* put all of the summarising of results info (finding best) into the AnalysisResults
* move subset writing out into reporter
* finish making reports fleshed out
* Final wiritng takes Analysis results
* think about reporter, how should it look? with config?

DONE
* move path creation into config
* make results member of scheme? or keep a paired list
* put all of the summarising of results info (finding best) into the AnalysisResults
* move subset writing out into reporter
* finish making reports fleshed out
* Final wiritng takes Analysis results
* think about reporter, how should it look? with config?


Done
____
- the numbers of columns are wrong when we warn that there are missing columns. Need to add 1 to the final number.
- we don't save phyml output by default now, but we have the option to
- we have universal line break support now
- flag a warning if ANYTHING in the .cfg file has changed. Do this by putting a copy of the .cfg file in the 'analysis' folder, loading it and comparing it to the current one
- fixed all scheme and subset number calculators
- mrbayes and raxml now options for model spec in the config file
- Get better .cfg parsing, so that we get useful error messages
- semicolons now needed, fixes some bugs in .cfg input
- add a more efficient Bell-number counter when counting schemes
- Use all CPU's default (rather than 1)
- Only use the user schemes if 'search' == 'user'
- check that Brett's implementation of source alignment and filtered alignment works.
- build initial tree and branchlengths NOT from the source alignment, but from the un-partitioned alignment. These can be different e.g. if I exclude some sites from all of my partitions. This is really important.
- Ordered scheme output in partitions in codon order (in scheme.py.write_summary)
- implemented Greedy search algorithm. Right now it works on whatever metric you specify in model_selection
- tidied up output of all_schemes.txt, best_schemes.txt, and the subset output files too
- Added model_selection option, AIC, AICc, or BIC now implemented
- Added branch_lengths option 'linked' or 'unlinked'
- Fixed calling of PhyML so that it actually constrains brlens
- PhyML constrained_lens option fixed by Stephane
- Added an error message if you specify a partition with sites that aren't in the alignment
- Fixed partition definition to include single sites
- optional charset at beginning of partition def 
